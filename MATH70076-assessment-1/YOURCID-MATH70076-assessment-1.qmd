---
title: "MATH70076: Data Science - Coursework 1"
subtitle: 'MSc in Statistics 2025/26, Imperial College London'
author: "06046525"
format:
  html:
    toc: true
    highlight: tango
    self-contained: true
  pdf: default
format-links: false
bibliography: "example.bib"
---

**Deadline:  Friday 10 October 2025 at 13:00.**

_For this assessment you should submit two files via the Imperial College VLE on Blackboard by the deadline stated above. Your files should be named as follows:_

- `YOURCID-MATH70076-assessment-1.pdf`: your rendered report,
- `YOURCID-MATH70076-assessment-1.zip`: a zip file containing the relevant source code to generate your report.

_All submitted materials should be clearly presented and be understandable as stand-alone documents._

_Please note that large files can take quite some time to upload. Ensure that you upload each document to the correct part of the learning space in a timely manner._

_This coursework is expected to take approximately 5 hours of individual effort and will be marked as Pass/Fail. Assessment criteria are given in the "set yourself up for success" boxes. Satisfying 15 or more out of these 20 criteria will constitute a pass grade._

_In submitting this assessment you certify that it is entirely your own work, apart from where otherwise acknowledged, and includes no plagiarism. Note that software tools are used as part of plagiarism detection._

-----
```{r install}
#| eval: false
#| echo: false
install.packages(c("rmarkdown", "knitr", "ggplot2", "stats"))
```
```{r setup, include = FALSE}
library(rmarkdown)
library(knitr)
library(ggplot2)
library(stats)

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
include_solutions <- TRUE
```

## Background 

### Generalised Pareto Distribution 

The Generalized Pareto Distribution (GPD) is a flexible family of continuous probability distributions that arises naturally in extreme value theory, particularly for modelling the distribution of excesses over a threshold. It is parametrised by a shape parameter $\xi \in \mathbb{R}$, a scale parameter $\sigma > 0$, and a location parameter $u \in \mathbb{R}$. Its cumulative distribution function (CDF) is given by

$$
F(x;\,\sigma,\xi, u) = 
\begin{cases}
1 - \left(1 + \dfrac{\xi (x-u)}{\sigma}\right)_+^{-1/\xi}, & \xi \neq 0, \, x \geq u; \; \\[1.2em]
1 - \exp\!\left(-\dfrac{x-u}{\sigma}\right), & \xi = 0, \, x \geq u;
\end{cases}
$$ {#eq-gpd-cdf}

where $x_+ = \max(x,0)$ and its probability density function (PDF) is

$$
f(x;\sigma,\xi,u) =
\begin{cases}
\dfrac{1}{\sigma}\left(1 + \dfrac{\xi (x-u)}{\sigma}\right)_+^{-1/\xi - 1}, & \xi \neq 0, \\[1.2em]
\dfrac{1}{\sigma}\exp\!\left(-\dfrac{x-u}{\sigma}\right), & \xi = 0,
\end{cases}
$$ {#eq-gpd-pdf}


defined on the same support as the CDF. The GPD encompasses a variety of tail behaviours:

- when $\xi > 0$ the GPD has heavy, slowly decaying tails, 
- in limiting case when $\xi \rightarrow 0$ the GPD reduces to an exponential distribution;
- when $\xi < 0$ the GPD has light, quickly decaying tails with a finite upper endpoint of $x^+ = u - \sigma / \xi$. 

### Probability Integral Transform

The probability integral transform states that if a random variable $X$ has a continuous cumulative distribution function $F_X(x)$, then the transformed variable $A = F_X(X)$ follows a uniform distribution on $[0,1]$. Conversely, if $F$ is an invertible function then $Y = F^{-1}_X(A)$ has the same distribution as $X$.

## Questions 

###  Question 1 

Derive an expression for the inverse cumulative distribution function (also known as the quantile function) $F^{-1}_X: [0,1] \rightarrow [u, x^+]$ of $X \sim \text{GPD}(u, \sigma, \xi)$. Your answer should refer to at least one equation given in the background material. 

::: {.callout-tip}
## Set yourself up for success

Does your answer contain:

- a few sentences of text describing your approach to the problem; 
- a reference to at least one equation from the background section;
- a correctly formatted LaTeX equation;
- a valid approach to the problem and correct expression.
:::


<!-- YOUR DERIVATION GOES HERE -->
\quad
We aim to obtain the inverse cumulative distribution function (CDF) of the Generalised Pareto Distribution (GPD). According to Probability Integral Transform, we know that if we let $A = F_X(X)$, and if $A \sim U[0,1]$, then the quantile function $F^{-1}_X: [0,1] \rightarrow [u, x^+]$ (inverse CDF function) can be derived from the @eq-gpd-cdf. Hence, we let $A\in [0,1]$ and solve for $x$.

The inverse CDF function could be divided into 2 situations. We start from the CDF of the GPD when $(\xi \neq 0)$:

$$
A = 1 - \left(1 + \frac{\xi(x - u)}{\sigma}\right)^{-1/\xi} \quad \iff
$$
$$
1 - A = \left(1 + \frac{\xi(x - u)}{\sigma}\right)^{-1/\xi} \quad \iff
$$
$$
(1 - A)^{-\xi} = 1 + \frac{\xi(x - u)}{\sigma} \quad \iff
$$
$$
- \frac{\xi(x - u)}{\sigma} = 1 - (1 - A)^{-\xi} \quad \iff
$$
$$
{\xi}(x - u) = {\sigma} ((1 - A)^{-\xi} - 1) \quad \iff
$$
$$
x - u = \frac{\sigma}{\xi} ((1 - A)^{-\xi} - 1) \quad \iff
$$
$$
x = u + \frac{\sigma}{\xi} \left[ (1 - A)^{-\xi} - 1 \right].
$$

Hence, for $\xi \neq 0$, the quantile function is

$$
F_X^{-1}(A) = u + \frac{\sigma}{\xi}\left[ (1 - A)^{-\xi} - 1 \right],  \quad A\in [0,1].
$$

For the other case $\xi = 0$, we derive the inverse CDF function from the @eq-gpd-pdf, again we let $A\in [0,1]$ and set $A = F_X(X)$, then we get:

$$
A = 1 - \exp\!\left(-\dfrac{x-u}{\sigma}\right) \quad \iff
$$
$$
 \exp\!\left(-\dfrac{x-u}{\sigma}\right) = 1 - A \quad \iff
$$
$$
-\dfrac{x-u}{\sigma} = \ln(1 - A) \quad \iff
$$
$$
x-u = -\sigma\left(\ln(1 - A)\right) \quad \iff
$$
$$
x = u -\sigma\ln(1 - A) \quad \iff
$$

Hence, for $\xi = 0$, the quantile function is

$$
F_X^{-1}(A) = u - \sigma \ln(1 - A), \quad A\in [0,1].
$$


### Question 2 

_For this question you should display the R code you use to define and document `qgpd()` within the main text of your report._

(a) Write and document your own function `qgpd()` to calculate quantiles of a given generalised Pareto distribution. Your function should have inputs and behaviour similar to the built-in R functions such as `qnorm()` and `qunif()` and check that inputs are in the correct format. 

(b) Suppose a random variable $X$ follows an generalised Pareto distribution with threshold parameter $u=1.5$, scale parameter $\sigma = 2$ and shape parameter $\xi = -0.4$. Use your function to find quantiles $x_p$ for $p = 0.5, 0.75, 0.99$ (i.e. for each $p$ find the value for which $\Pr(X < x_p) = p$).


:::{.callout-tip}
## Set yourself up for success

Does your answer: 

- contain a valid R function definition;
- document the expected inputs, outputs and behaviours of that function;
- check the validity of inputs;
- handle any edge-cases in an appropriate way;
- return the correct quantile values? 

:::
for (a),
```{r}
#######################
# Question 2
#######################
# Part A --------------------------
#' Quantile function of the Generalised Pareto Distribution (GPD)
#'
#' Calculate the quantiles (inverse cumulative distribution function) 
#' of a given GPD with given parameters (shape parameter xi, 
#' scale parameter sigma, and shape parameter xi).
#'
#' @param p Vector of probabilities (0 <= p <= 1).
#' @param u Vector of threshold/location (numeric parameter).
#' @param sigma Vector of scale (positive numeric parameter).
#' @param xi Vector of shape (numeric parameter).
#'
#' @return A vector of quantiles corresponding to the input probabilities 
#' and given values of parameters.
#'
#' @export
#' @examples
#' qgpd(c(0.5, 0.75, 0.99), u = 1.5, sigma = 2, xi = -0.4)
#'
qgpd <- function(p, u, sigma, xi) {
  # input checks
  stopifnot(
  is.numeric(p),
  all(p >= 0 & p <= 1),
  is.numeric(xi),
  length(xi) == 1,
  is.numeric(sigma),
  length(sigma) == 1,
  sigma > 0,
  is.numeric(u),
  length(u) == 1
  )

  # main computation
  if (xi == 0) {
    q <- u - sigma * log(1 - p)
  } else {
    q <- u + (sigma / xi) * ((1 - p)^(-xi) - 1)
  }

  return(q)
}
```

For (b),
```{r}
# Part B --------------------------
# set values for given parameters
p <- c(0.5, 0.75, 0.99)
u <- 1.5
sigma <- 2
xi <- -0.4

# use qgpd() function to calculate the quantiles for X_p
quantiles <- qgpd(p, u = u, sigma = sigma, xi = xi)
quantiles
```

### Question 3

_For this question, all R code should be displayed only within the appendix, not in the main report._

The file `gpd_samples.csv` contains six sets of random variates generated from different generalised Pareto distributions. The details of the generalised Pareto distributions used are summarised in `gpd_parameters.csv`. Unfortunately some of the parameter sets were recorded incorrectly. 

Within a single figure, construct a series of quantile-quantile plots to identify which datasets are inconsistent with their stated distributions. You should both justify your conclusions and describe your level of confidence in your findings. 

::: {.callout-tip}
## Set yourself up for success 

Does your solution contain: 

- at least one quantile-quantile plot;
- six qq-plots in a single figure;
- use of loops, vectorisation, or function definitions to avoid repetitive code.
- figures with clear text, useful captions and appropriate visual mapping of data;
- a few paragraphs describing and justifying your findings and referencing the figure;

:::

<!-- YOUR ANSWER GOES HERE --> 
```{r}
#| echo: false
#| layout-ncol: 3
#| layout-nrow: 2
#| fig-width: 9
#| fig-height: 6
#| label: fig-qqplots
#| fig-cap: "QQ plots for the six different GPD datasets compared 
#| to their stated distributions."
#| fig-subcap:
#|   - "Set a"
#|   - "Set b"
#|   - "Set c"
#|   - "Set d"
#|   - "Set e"
#|   - "Set f"
#######################
# Question 3
#######################
samples <- read.csv("gpd_samples.csv")
parameters <- read.csv("gpd_parameters.csv")
View(samples)
View(parameters)

# Plot with the use of loops
datasets <- unique(samples$set_id)

for (a in datasets) {
  subset_data <- samples[samples$set_id == a, ]  
  x <- subset_data$value                        

  n <- length(x)
  x_sorted <- sort(x)
  p <- (1:n) / (n + 1)  

  param <- parameters[parameters$id == a, ]
  u <- param$u
  sigma <- param$sigma
  xi <- param$xi
  u_sim <- param$u_sim
  sigma_sim <- param$sig_sim
  xi_sim <- param$xi_sim

  q_theoretical <- qgpd(p, u = u, sigma = sigma, xi = xi)
  q_sim <- qgpd(p, u = u_sim, sigma = sigma_sim, xi = xi_sim)
  plot(q_theoretical, x_sorted, main = "", 
         cex.axis = 1.4, cex.lab = 1.4, pch = 16,
         xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
  abline(0, 1, col = "red", lty = 2)
  points(q_sim, x_sorted, pch = 17, col = "blue")
  legend("topleft",
       legend = c("recorded parameters", "simulated parameters"),
       pch = c(16, 17), col = c("black", "blue"), bty = "n", cex = 2)
}
```
The @fig-qqplots above shows six QQ plots in one figure comparing the sample quantiles with theoretical quantiles based on both the recorded and the simulated parameter sets. The 45 sred dashed line represents perfect agreement between theoretical and empirical quantiles.

For Set b (@fig-qqplots-2), the points of recorded parameters (black) scatter closely along the abline, which indicates consistency with the stated distribution. In addition, the recorded and simulated parameter curves perfectly overlap along the abline, suggesting that the recorded parameters were accurately specified. Hence, our confidence in this conclusion is high as both parameterisations produce consistent fits.

Additionally, Sets c (@fig-qqplots-3) and Set f (@fig-qqplots-6) demonstrate moderate deviations when using the recorded parameters, particularly at higher quantiles. Both sets align closely with the simulated parameters (blue points), so both parameter sets yield almost identical distributional behaviour. Thus, we can infer that the recorded parameters were likely specified correctly. The deviation may arise from the sampling variability, because the amount of data for these two sets is low (20 and 98). The level of confidence is lower compared to Set b. Because when both sets perform similarly (both showing deviations), the evidence against reporting errors is weaker. Although the recorded parameters are not clearly incorrect, the limited data reduce our confidence in the conclusion.

In contrast, the plots for Set a, d and e present noticeable departure from the 45 reference line, which suggests the parameters were likely recorded incorrectly. For Set a (@fig-qqplots-1), recorded values deviate from the reference line while simulated values lie closer to the reference line. The distinct divergence between black and blue points provides strong evidence that the recorded parameters were inaccurately reported.

Moreover, Set d (@fig-qqplots-4) also displays deviation from the reference line, but the recorded and simulated points align closely with each other. Since both parameter sets provide similar fits, the evidence for parameter errors is weakened, and our confidence in this conclusion is less compared to Set a.

Finally, for Set e (@fig-qqplots-5), there are substantial and irregular departures from the abline to both parameter sets. This suggests that the fit qualities for both quantiles are poor. Hence, our conclusions to Set e remain uncertain, with only moderate to low level of confidence.


### Question 4

_For this question, all R code should be displayed only within the appendix, not in the main report._

A hydrologist is interested in understanding the river flow at a location that is historically prone to flooding. There is a river flow gauge nearby which measures river flow in units of cubic meters per second ($\text{m}^3/\text{s}$ or cumecs). Based on her knowledge of other rivers, the hydrologist proposes that for this river gauge:

 - the distribution of river flow values is constant over time 
 - for river flows exceeding 75 cumecs, it is appropriate to model these data as independent and identically distributed GPD($\sigma =29.7$, $\xi=0.62$, $u = 0$). 

Use `riverflow_2015-2024.csv` to conduct an exploratory investigation of whether these proposals are valid for the dataset provided. Summarise your findings in 250-350 words, supporting these with a collection of 4 visualisations/figures. 


::: {.callout-tip}
## Set yourself up for success 

Does your answer contain: 

- 400-500 words of text clearly describing your choice of visualisations, their interpretation and your conclusions about the validity of each assumption,
- A series of 4 visualisations / figures,
- A varied and appropriate choice of figures to investigate each of the hydrologist's proposals,
- Figures with clear text, useful captions and appropriate visual mapping of data;
- At least one reference to each visualisation within the main text.
:::


<!-- YOUR INVESTIGATION GOES HERE --> 
```{r}
#| include: false
#######################
# Question 4
#######################
riverflow <- read.csv("riverflow_2015_2024.csv")
View(riverflow) 

sum(riverflow$is_extreme == "True") ## Number of True (is.extreme) is 300
sum(riverflow$flow > 75) ## But we only have 158 values exceeding 75 cumecs
sum(riverflow$flow <= 75 & riverflow$is_extreme == "True") 
## There are too many entries lower than 75 but record as True,
## thus we will not extract values according to "is_extreme" column.

```
We first examine the validity of the proposal that “the distribution of river flow values is constant over time”.  The proposal implies that the statistical characteristics of river flow data, for example, its mean, variance, and shape of the distribution remained unchanged across years. To examine this, we produce a box plot and a density plot using *ggplot2* [@Ross2018] to evaluate whether there is a systematic trend in the mean or variability of the annual river flow’s values. 
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 3
#| label: fig-boxplot
#| fig-cap: "Boxplot to examine the yearly distribution of baseline mean."
## Figure 1 (Boxplot)
# Extract year from Date
riverflow$date <- as.Date(riverflow$date)
riverflow$Year <- format(riverflow$date, "%Y")

# Boxplot of baseline_mean by year
ggplot(riverflow, aes(x = Year, y = baseline_mean), cex.lab = 1.2) +
  geom_boxplot(fill = "lightblue", color = "black") +
  theme_light() +
  labs(title = "Yearly Distribution of Baseline Mean of River Flow",
       y = "Baseline Mean of River Flow (m³/s)", x = "Year") 
```
The boxplot @fig-boxplot demonstrates a distribution of yearly river flow averages and helps us to examine the stability of central tendency and spread of data. We can see a clear long-term increase in flow magnitudes over the years. Additionally, the median flow values show a continuous upward trend in the value, which provides strong evidence against hydrologist’s assumption of a stationary mean. The interquartile ranges are relatively stable, which gives evidence for largely constant variability of flow data. Overall, the figure indicates that while the spread of flow values does not change markedly, their central tendency has increased over the years, which contradicts the hydrologist’s first proposal.
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 2.8
#| fig-pos: "H"
#| label: fig-density
#| fig-cap: "Density plot to visualise the shape of river flow data each year."
# Figure 2 (Density plot)
ggplot(riverflow, aes(x = flow, colour = Year), cex.lab =1.4) +
  geom_density() +
  coord_cartesian(xlim = c(0, quantile(riverflow$flow, 0.99))) +
  theme_light() +
  labs(x = "River Flow (m³/s)", y = "Density",
       title = "Density Plot of River flow by Year")
```
@fig-density displays the kernel density estimates of river flow for each year between 2015 and 2024. Kernel density estimation provides a smooth, nonparametric representation of the underlying probability density without assuming a specific functional for our data [@Tollefson2021]. It illustrates the overall shape of the flow values for each year and captures the underlying patterns and properties of distribution, like skewness, tail behaviours. The distributions of each year share a broadly similar right-skewed shape. However, the peaks of the densities shift rightward over time and the degree of right skewness decreases. This suggests a progressive increase in annual flow levels and a slight reduction in tail heaviness of data over the years. These patterns imply that the distribution of river flow is not constant over time. As a result, both the boxplot and density plot provide evidence that the hydrologist’s proposal of a time-invariant distribution is not supported by the data.

We then evaluate the second proposal: “for river flows exceeding 75 cumecs, it is appropriate to model these data as independent and identically distributed GPD(sigma = 29.7, xi = 0.62, u = 0). The proposal suggests that all flows above the threshold of 75 cumecs follow a same Generalised Pareto Distribution (GPD) with those specified shape and scale parameters, and these exceedances have no serial dependence with each other.
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 4
#| label: fig-qqplot2
#| fig-cap: "QQ plot to examine the GPD's goodness of fit to exceedances."
## Figure 3 (QQ plot)
u <- 75
exceed <- riverflow$flow[riverflow$flow > u] - u

u_simu <- 0
sigma_simu <- 29.7
xi_simu <- 0.62

n <- length(exceed)
p <- (1:n) / (n + 1)
x_sorted <- sort(exceed)

# Calculate the theoretical quantiles using our qgpd() function
q_theoretical_sim <- qgpd(p, u = u_simu, sigma = sigma_simu, xi = xi_simu)

plot(q_theoretical_sim, x_sorted, 
     main = "QQ Plot for Exceedances (flow > 75)",
     xlab = "Theoretical Quantiles",
     ylab = "Observed Quantiles",
     pch = 16, 
     col = rgb(0,0,0,0.5),
     cex.lab = 1,
     cex.main= 1)
abline(0, 1, col = "red", lwd = 2, lty = 2)
legend("topleft",
       legend = c("Observed exceedances", "45° reference line"),
       pch = c(16, NA), lty = c(NA, 2), col = c(rgb(0,0,0,0.5), "red"),
       bty = "n")
```
To assess the suitability of proposed GPD model, we extract the exceedances above 75 cumecs and compared their empirical quantiles with theoretical quantiles computed from GPD(sigma = 29.7, xi = 0.62). In the QQ plot below (@fig-qqplot2), the points of sample quantiles closely scatter along the reference line, with only slight deviations in the upper tail. Due to limited data, such departures are expected reasonably in extreme-value modelling. Overall, the plot indicates that the proposed GPD model with specified parameters capture the tail behaviour of the river flow data reasonably well.
```{r}
#| echo: false
#| layout-ncol: 3
#| layout-nrow: 1
#| fig-width: 7
#| fig-height: 5
#| label: fig-exceed
#| fig-cap: "Time series plot & ACF plots to examine the i.i.d. assumptions of 
#| river flow values."
#| fig-subcap:
#|   - "Time series plot of flow > 75 cumecs"
#|   - "ACF plot of flow > 75 cumecs"
#|   - "ACF plot of all flow values"
## Figure 4 (Time series plot & ACF plots)
plot(exceed, type = "l", col = "black",
     xlab = "Date", ylab = "River Flow (m³/s)",
     main = "Time Series Plot of River Flow")

acf(exceed, main = "ACF of Flows Exceeding 75 cumecs")
acf(as.numeric(riverflow$flow), main = "ACF of All River Flows")
```
To validate the “independent and identically distributed (i.i.d.)” assumption, we produce three visualisations in one figure (@fig-exceed). The trace plot (@fig-exceed-1) displays exceedances over time and demonstrates no evident systematic trends and volatility clustering patterns except for one isolated peak point of river flow. This indicates the distribution of exceedances is relatively stable and particularly supports the "identically distributed" assumption.

In addition, we utilise the autocorrelation function (ACF) plots (@fig-exceed-2) to investigate the dependency of exceedances data. The ACF plots conduct correlation diagnostics of time series and capture patterns of serial dependence [@Tollefson2021]. There is no bar extending beyond 95% confidence bounds in @fig-exceed-2, and no geometrical and gradual decay in bars. Besides, there are no periodic spikes at specified lags. Hence, the values shows no autocorrelation problems and the plot supports our conclusion from the trace plot, which there is no long-run dependency in the exceedances. Overall, @fig-exceed-1 and @fig-exceed-2 give strong support to the hydrologist’s proposal that the river flow exceeding 75 cumecs can be treated as independent and identically distributed. 

Lastly, the ACF plot can also be used to examine all river flow's values. With some notable spikes above confidence bounds and a gradual decline in the bar's heights, the @fig-exceed-3 reinforces our earlier conclusion towards the first proposal of the hydrologist that the full series of flow data does not have a constant distribution over time.

::: {.callout-tip}
## Set yourself up for success 

- Does your document render without any formatting issues? 
:::

_End of Assessment._


# Code Appendix {#sec-code-appendix}

```{r ref.label=knitr::all_labels()}
#| echo: true
#| eval: false
#| code-fold: true
```






